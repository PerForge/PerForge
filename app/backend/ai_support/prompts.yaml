prompts:
- id: response_time_single_test
  name: Response time graph of a single test
  type: default
  place: graph
  prompt: |
    ###Task: follow the instructions below to ANALYZE the graph and PROVIDE observations corresponding to constraints
    ###Instructions:
    - Assess the trends of each response time line.
    - Response times should remain stable. Minor fluctuations in response times are acceptable.
    - Explicitly identify any spikes or significant deviations in each metric.
    ###Constraints: 
    - Provide one observation per metric as a bullet list, without an opening statement or conclusion, and refrain from using prefixed descriptors such as 'Observations.'"
    - Your output should follow the following structure if there is no performance issue for a metric:
      - The [metric] is consistently stable [with minimal fluctuations/without fluctuations].
    - Your output should follow the following structure if there is performance issue for a metric:
      - The [performance issue description], indicating performance issue.
    ###Input: response time metric graph
prompts:
- id: throughput_single_test
  name: Throughput graph of a single test
  type: default
  place: graph
  prompt: |
    ###Task: follow the instructions below to ANALYZE the graph and PROVIDE observations corresponding to constraints
    ###Instructions:
    - Assess the trends of each throughput line.
    - Throughput should remain stable. Minor fluctuations in throughput are acceptable.
    - Explicitly identify any performance issue in each metric.
    ###Constraints: 
    - Provide one observation per metric as a bullet list, without an opening statement or conclusion, and refrain from using prefixed descriptors such as 'Observations.'"
    - Your output should follow the following structure if there is no performance issue for a metric:
      - The [metric] is consistently stable [with minimal fluctuations/without fluctuations].
    - Your output should follow the following structure if there is performance issue for a metric:
      - The [performance issue description], indicating performance issue.
    ###Input: Throughput metric graph
- id: graph_comparison_of_tests
  name: Graph comparison of tests
  type: default
  place: graph
  prompt: |
    Context: You are provided with a performance testing graph featuring two lines: a solid line indicating the current test and a dotted line representing the baseline test.
    Task: Analyze the graph, compare the current test against a baseline and provide observations concerning the current test in relation to the baseline.
    Please consider the following:
      - Identify each line by its label and color.
      - Evaluate whether the current level aligns with the baseline.
      - Assess the stability of the current trend, specifying the time and percentage range if unstable, ignoring minor fluctuations.
    Constraints:
      - Provide the most important observations in a bulleted list without introductory statements or conclusions.
      - If the metric is comparable and there are no observed degradations, the test is considered successful. In this case, the observation should contain only the following statement: '[Metric name] is comparable with the baseline test and the overall trend of the current test is stable.'
      - If the current test isn't comparable or there are observed degradations, the observation should contain only the following statements:
        '[Metric name] is [comparable/not comparable] with the baseline test and the overall trend of the current test is [stable/not stable].'
        '[Provide your high-level observations of degradations up to 2 sentences].'
- id: table_comparison_of_tests_response_time
  name: Table comparison of tests response time
  type: default
  place: graph
  prompt: |
    Task: Analyze the table.
    Instructions:
      - Determine transactions with positive value of difference is more than 300 milliseconds and mark them as degraded.
      - If there aren't degraded transactions, then the output should contain only the following statement: 'For all transactions, the response time remained at the same level.'
      - If there are degraded transactions, then the output should contain only the following statements:
        'For most transactions, the response time remained at the same level, except the following transactions:
        - {{Transaction name}} shows a degradation of {{degradation milliseconds}} milliseconds.'
- id: aggregated_data_of_a_single_test
  name: Aggregated data of a single test
  type: default
  place: aggregated_data
  prompt: |
    Task: Analyze the metrics.
    Constraints: Provide your output using the following structure; do not use any other format. Replace [] with real values.
    Instructions:
      - Provide requests with high error rate. If there are requests with an error rate greater than 2%, follow this structure:
        - The request [request name] has a notably high percentage of errors at [percent value]%.
      - If all requests have an error rate less than 2%, use this structure:
        - No requests with high error rate.
      - Provide the top 5 slowest requests. Structure in a bullet list:
        - Top 5 slowest requests (Based on median):
          - [request name]: median response time of [value] ms.
- id: template_of_a_single_test
  name: Template of a single test
  type: default
  place: template
  prompt: |
    Context: You are provided with a set of performance test observations, including graphs and test data analysis.
    Task: Create a comprehensive report, that should encapsulate key findings, and actionable recommendations to provide a clear overview of the system's performance and stability.
    Constraints: Provide your output using the following structure, shared below between @@@@ characters; do not use any other format. Do not include @@@@ markers in the output. Replace the square brackets [] with the actual values.
    @@@@
    Summary:
      The performance testing results indicate that the system [performs well with no significant performance issues/shows both strengths and areas for improvement/performs very poorly, with significant issues]. The key areas for improvement include [highlight areas].

    Analysis:
      - [Provide a highlevel overview of the behavior of throughput]
      - [Provide a highlevel overview of the behavior of response times]
      - [Provide a highlevel overview of the behavior of CPU usage]
      - [Provide a highlevel overview of the behavior of Memory usage]
      - The test results are [satisfactory/not satisfactory] as only [value]% of the Non-Functional Requirements (NFRs) are met.

    Top 5 slowest requests:
      - [request name]: median response time of [value] ms.

    Requests with high error rate:
    [If there are requests with a high error rate, include them]

    Requests that do not meet NFRs:
    [If there are requests that don't meet the NFRs, include them]

    Recommendations:
      - [Provide recommendations for addressing any identified issues. Ensure that each recommendation is clearly stated and supported by the data].
    @@@@

    Observations from aggregated data analysis:
      [aggreagted_data_analysis]

    Observations from graphs analysis:
      [graphs_analysis]

    Observations from NFRs comparison.
      [nfr_summary]
- id: template_comparison_tests
  name: Template comparison tests
  type: default
  place: template
  prompt: |
    Context: You are provided with a set of stability performance regression test results, including analysis of graphs, aggregated data and NFRs.
    Task: Create a detailed regression test report that should present the key regression findings and practical recommendations to gain a clear understanding of the performance and stability of the system.
    Constraints: Provide your output using the following structure, shared below between @@@@ characters; do not use any other format. Do not include @@@@ markers in the output. Replace the square brackets [] with the actual values.
    @@@@
    Summary:
      The performance testing results are [comparable with no significant performance issues/comparable with areas for improvement/uncomparable, with significant issues]. The key areas for improvement include [highlight areas].

    Analysis:
      - [Provide a highlevel overview of the behavior of throughput]
      - [Provide a highlevel comparing overview of the behavior of response times only in one sentence]
      - [Provide a highlevel overview of the behavior of CPU usage only in one sentence]
      - [Provide a highlevel overview of the behavior of Memory usage only in one sentence]
      - The test results are [satisfactory/not satisfactory] as only [value]% of the Non-Functional Requirements (NFRs) are met.

    Top 5 slowest requests:
      - [request name]: median response time of [value] ms.

    Requests with high error rate:
      [If there are requests with a high error rate, include them]

    Requests that do not meet NFRs:
      [If there are requests that don't meet the NFRs, include them]

    Recommendations:
      - [Provide recommendations for addressing any identified issues. Ensure that each recommendation is clearly stated and supported by the data].
    @@@@

    Observations from aggregated data analysis:
      [aggregated_data_analysis]

    Observations from graphs analysis:
      [graphs_analysis]

    Observations from NFRs analysis:
      [nfr_summary]
- id: template_group
  name: Template group
  type: default
  place: template_group
  prompt: |
    Task: Review the results of multiple tests provided below and create short high-level summary of each test.
    Constraints: Provide your output using the following structure, shared below between @@@@ characters; do not use any other format. Do not include @@@@ markers in the output. Replace the square brackets [] with the actual values.
    @@@@
    Summary:
      - The tests results are [satisfactory/not satisfactory].
      - [Provide a highlevel overview of the performance issues].
    @@@@
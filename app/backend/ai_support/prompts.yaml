prompts:
- id: response_time_graph
  name: Response time graph
  type: default
  place: graph
  prompt: |
    ###Task: follow the instructions below to ANALYZE the graph and PROVIDE observations corresponding to constraints
    ###Instructions:
    - Assess the trends of each response time line.
    - Response times should remain stable. Minor fluctuations in response times are acceptable.
    - Explicitly identify any spikes or significant deviations in each metric.
    ###Constraints: 
    - Provide one observation per metric as a bullet list, without an opening statement or conclusion, and refrain from using prefixed descriptors such as 'Observations.'
    - Your output should follow the following structure if there is no performance issue for a metric:
      - The [metric] is consistently stable [with minimal fluctuations/without fluctuations].
    - Your output should follow the following structure if there is performance issue for a metric:
      - The [performance issue description], indicating performance issue.
    ###Input: response time metric graph
- id: throughput_graph
  name: Throughput graph
  type: default
  place: graph
  prompt: |
    ###Task: follow the instructions below to ANALYZE the graph and PROVIDE observations corresponding to constraints
    ###Instructions:
    - Assess the trends of each throughput line.
    - Throughput should remain stable. Minor fluctuations in throughput are acceptable.
    - Explicitly identify any performance issue in each metric.
    ###Constraints: 
    - Provide one observation per metric as a bullet list, without an opening statement or conclusion, and refrain from using prefixed descriptors such as 'Observations.'
    - Your output should follow the following structure if there is no performance issue for a metric:
      - The [metric] is consistently stable [with minimal fluctuations/without fluctuations].
    - Your output should follow the following structure if there is performance issue for a metric:
      - The [performance issue description], indicating performance issue.
    ###Input: Throughput metric graph
- id: cpu_usage_graph
  name: CPU usage graph
  type: default
  place: graph
  prompt: |
    ###Task: follow the instructions below to ANALYZE the graph and PROVIDE observations corresponding to constraints
    ###Instructions:
    - Assess the trends of each CPU usage line.
    - CPU usage line should remain stable. Minor fluctuations in CPU usage are acceptable.
    - Explicitly identify any performance issue in each metric.
    ###Constraints: 
    - Provide one observation per metric as a bullet list, without an opening statement or conclusion, and refrain from using prefixed descriptors such as 'Observations.'
    - Your output should follow the following structure if there is no performance issue for a metric:
        - The [metric] is consistently stable [with minimal fluctuations/without fluctuations].
    - Your output should follow the following structure if there is performance issue for a metric:
        - The [performance issue description], indicating performance issue.
    ###Input: CPU usage metric graph
- id: memory_usage_graph
  name: Memory usage graph
  type: default
  place: graph
  prompt: |
    ###Task: follow the instructions below to ANALYZE the graph and PROVIDE observations corresponding to constraints
    ###Instructions:
    - Assess the trends of each Memory usage line.
    - Memory usage line should remain stable. Minor fluctuations in Memory usage are acceptable.
    - Explicitly identify any performance issue in each metric.
    ###Constraints: 
    - Provide one observation per metric as a bullet list, without an opening statement or conclusion, and refrain from using prefixed descriptors such as 'Observations.'
    - Your output should follow the following structure if there is no performance issue for a metric:
        - The [metric] is consistently stable [with minimal fluctuations/without fluctuations].
    - Your output should follow the following structure if there is performance issue for a metric:
        - The [performance issue description], indicating performance issue.
    ###Input: Memory usage metric graph
- id: response_time_comparison_graph
  name: Response time comparison graph
  type: default
  place: graph
  prompt: |
    ###Task: Follow the instructions below to analyze the graph, COMPARE the current test against a baseline, and PROVIDE observations corresponding to constraints and concerning the current test in relation to the baseline.
    ###Context: You are provided with a performance testing graph featuring two lines: a solid line indicating the current test and a dotted line representing the baseline test.
    ###Instructions:
      - Assess the trends of each response time line.
      - Evaluate if the current response time level is comparable to the baseline.
      - Assess the stability of the current response time line. Minor fluctuations are acceptable.
    ###Constraints: 
      - Be concise and provide your observation in one sentence, without introductory statements or conclusions.
      - If the metric is comparable and there are no observed degradations, the test is considered successful. In this case, the observation should follow the following structure: [Metric name] is comparable with the baseline test and the overall trend of the current test is stable.
      - If the current test isn't comparable or there are observed degradations, the observation should follow the following structure: [Metric name] is not comparable with the baseline test since [describe performance issue].
- id: throughput_comparison_graph
  name: Throughput comparison graph
  type: default
  place: graph
  prompt: |
    ###Task: Follow the instructions below to analyze the graph, COMPARE the current test against a baseline, and PROVIDE observations corresponding to constraints and concerning the current test in relation to the baseline.
    ###Context: You are provided with a performance testing graph featuring two lines: a solid line indicating the current test and a dotted line representing the baseline test.
    ###Instructions:
      - Assess the trends of each throughput line.
      - Evaluate if the current throughput level is comparable to the baseline.
      - Assess the stability of the current throughput line. Minor fluctuations are acceptable.
    ###Constraints: 
      - Be concise and provide your observation in one sentence, without introductory statements or conclusions.
      - If the metric is comparable and there are no observed degradations, the test is considered successful. In this case, the observation should follow the following structure: [Metric name] is comparable with the baseline test and the overall trend of the current test is stable.
      - If the current test isn't comparable or there are observed degradations, the observation should follow the following structure: [Metric name] is not comparable with the baseline test since [describe performance issue].
- id: response_time_comparison_table
  name: Response time comparison table
  type: default
  place: graph
  prompt: |
    ###Task: FOLLOW the instructions below to ANALYZE the table and PROVIDE observations
    ###Instructions:
      - Identify transactions where the absolute difference value (Diff) is more than +300ms and the difference is positive (indicating degradation) and mark them as degraded. Ensure to consider the units (ms or s) for both baseline and current values.
      - If there aren't degraded transactions, then the output should contain only the following statement: 'For all transactions, the response time remained at the same level.'
      - If there are degraded transactions, then the output should contain only the following statements:
        'For most transactions, the response time remained at the same level, except the following transactions:
        - {{Transaction name}} shows a degradation of {{degradation milliseconds}} milliseconds.'
- id: template_for_the_test
  name: Template for the test
  type: default
  place: template
  prompt: |
    Context: You are provided with a set of performance test observations, including graphs and test data analysis.
    Task: Create a comprehensive report, that should encapsulate key findings, and actionable recommendations to provide a clear overview of the system's performance and stability.
    Constraints: Provide your output using the following structure, shared below between @@@@ characters; do not use any other format. Do not include @@@@ markers in the output. Replace the square brackets [] with the actual values.
    @@@@
    Summary:
      The performance testing results indicate that the system [performs well with no significant performance issues/shows both strengths and areas for improvement/performs very poorly, with significant issues]. The key areas for improvement include [highlight areas].

    Analysis:
      - [Provide a highlevel overview of the behavior of throughput]
      - [Provide a highlevel overview of the behavior of response times]
      - [Provide a highlevel overview of the behavior of CPU usage]
      - [Provide a highlevel overview of the behavior of Memory usage]
      - The test results are [satisfactory/not satisfactory] as only [value]% of the Non-Functional Requirements (NFRs) are met.

    Top 5 slowest requests:
      - [request name]: median response time of [value] ms.

    Requests with high error rate:
    [If there are requests with a high error rate, include them]

    Requests that do not meet NFRs:
    [If there are requests that don't meet the NFRs, include them]

    Recommendations:
      - [Provide recommendations for addressing any identified issues. Ensure that each recommendation is clearly stated and supported by the data].
    @@@@

    Observations from aggregated data analysis:
    [aggreagted_data_analysis]

    Observations from graphs analysis:
    [graphs_analysis]

    Observations from NFRs comparison.
    [nfr_summary]
- id: template_for_comparing_tests
  name: Template for comparing tests
  type: default
  place: template
  prompt: |
    Context: You are provided with a set of stability performance regression test results, including analysis of graphs, aggregated data and NFRs.
    Task: Create a detailed regression test report that should present the key regression findings and practical recommendations to gain a clear understanding of the performance and stability of the system.
    Constraints: Provide your output using the following structure, shared below between @@@@ characters; do not use any other format. Do not include @@@@ markers in the output. Replace the square brackets [] with the actual values.
    @@@@
    Summary:
      The performance testing results are [comparable with no significant performance issues/comparable with areas for improvement/uncomparable, with significant issues]. The key areas for improvement include [highlight areas].

    Analysis:
      - [Provide a highlevel overview of the behavior of throughput]
      - [Provide a highlevel comparing overview of the behavior of response times only in one sentence]
      - [Provide a highlevel overview of the behavior of CPU usage only in one sentence]
      - [Provide a highlevel overview of the behavior of Memory usage only in one sentence]
      - The test results are [satisfactory/not satisfactory] as only [value]% of the Non-Functional Requirements (NFRs) are met.

    Top 5 slowest requests:
      - [request name]: median response time of [value] ms.

    Requests with high error rate:
      [If there are requests with a high error rate, include them]

    Requests that do not meet NFRs:
      [If there are requests that don't meet the NFRs, include them]

    Recommendations:
      - [Provide recommendations for addressing any identified issues. Ensure that each recommendation is clearly stated and supported by the data].
    @@@@

    Observations from aggregated data analysis:
    [aggregated_data_analysis]

    Observations from graphs analysis:
    [graphs_analysis]

    Observations from NFRs analysis:
    [nfr_summary]
- id: template_group
  name: Template group
  type: default
  place: template_group
  prompt: |
    Task: Review the results of multiple tests provided below and create short high-level summary of each test.
    Constraints: Provide your output using the following structure, shared below between @@@@ characters; do not use any other format. Do not include @@@@ markers in the output. Replace the square brackets [] with the actual values.
    @@@@
    Summary:
      - The tests results are [satisfactory/not satisfactory].
      - [Provide a highlevel overview of the performance issues].
    @@@@
- id: aggregated_data
  name: Aggregated data
  type: default
  place: aggregated_data
  prompt: |
    ###Task: follow the instructions below to ANALYZE the metrics and PROVIDE observations corresponding to constraints
    ###Constraints: Provide your output using the following structure; do not use any other format. Replace [] with real values.
    ###Instructions:
      - Provide requests with high error rate. If there are requests with an error rate greater than 2%, follow this structure:
        - The request [request name] has a notably high percentage of errors at [percent value]%.
      - If all requests have an error rate less than 2%, use this structure:
        - No requests with high error rate.
      - Provide the top 5 slowest requests. Structure in a bullet list:
        - Top 5 slowest requests (Based on median):
          - [request name]: median response time of [value] ms.
- id: system_message
  name: System message
  type: default
  place: system
  prompt: |
    You are a skilled Performance Analyst with strong data analysis expertise. Please help analyze the performance test results.
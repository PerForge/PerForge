from app.backend import pkg

class Prompt:
    def __init__(self, project_id):
        self.project_id = project_id
        self.set_default_prompts()
        self.aggreagted_table = pkg.get_prompt_by_type(project_id, "aggreagted_table")
        self.graph            = pkg.get_prompt_by_type(project_id, "graph")
        self.template         = pkg.get_prompt_by_type(project_id, "template")
        self.template_group      = pkg.get_prompt_by_type(project_id, "template_group")
    
    def set_default_prompts(self):
        default_graph_prompt = "Role: Senior performance analyst\r\nContext: You are provided with a graph that includes two lines: Requests Per Second (RPS - yellow line), and Active Users (green line). The x-axis represents time. The left y-axis represents requests per second, and the right y-axis represents the number of active users. \r\nTask: analyze throughout graph and provide observations.\r\nPlease consider the following check-list:\r\n- Based on your observations, determine whether the throughput is stable throughout the test.\r\n- Analyze the trends of the RPS line. If the Active Users line remains constant, then the  RPS line should also remain constant and stable. However, if the number of active users is on an upward trend, the RPS lines should proportionally increase as well.\r\n- Identify significant fluctuations or spikes. Ignore slight fluctuations.\r\n- Don't note in observations any sudden increases towards the end of the test, if they exist. They're likely related to the ramping down phase of the test.\r\n- Remember to apply mathematical rigor and clear data-driven logic throughout your analysis. \r\nConstraints: Provide up to 5 most important observations as a bullet list without an opening statement or conclusion and without prefixed descriptions such as \"Observations\"."
        aggreagted_table     = "Role: Senior performance analyst\r\nContext: You are provided with a table containing metrics for each request: Requests Per Minute, Percent of Errors, Count of Executions, Average Response Time, Max Response Time, Min Response Time, 50th Percentile Response Time, 75th Percentile Response Time, 90th Percentile Response Time, and Standard Deviation of Response Time. \r\nTask: analyze the metrics and provide observations.\r\nPlease consider the following check-list:\r\n- \"all\" refers to metrics aggregated for all requests, so it applies to the entire test.\r\n- Examine the Percent of Errors for each request to identify any requests with high error rates.\r\n- Provide top 5 slowest requests.\r\n- Remember to apply mathematical rigor and clear data-driven logic throughout your analysis.\r\nConstraints: Provide your output using the following structure; do not use any other format. Replace [] with real values:\r\n- The request [request name] has a notably high percentage of errors at [percent value]%.\r\n- 75%-tile response time for 'all' requests, stands at [75Pct value] ms.\r\n- Average throughput for 'all' requests, stands at [rpm value] r/s.\r\n- Top 5 slowest requests (Based on 75%-tile):\r\n   - [request name]: 75%-tile response time of [value] ms."
        summary_template     = "Role: Senior performance analyst\nContext: You are provided with a set of performance test observations, including graphs and test data analysis.\nTask: Create a comprehensive report, that should encapsulate key findings, and actionable recommendations to provide a clear overview of the system's performance and stability.\nConstraints: Provide your output using the following structure, shared below between @@@@ characters; do not use any other format. Do not include @@@@ markers in the output. Replace the square brackets [] with the actual values.\n@@@@\nSummary:\nThe performance testing results indicate that the system [performs well with no significant performance issues/shows both strengths and areas for improvement/performs very poorly, with significant bottlenecks that prevent the system from operating efficiently]. The key areas for improvement include [highlight areas]. The recommended actions are expected to [brief summary of expected action items].\n\nAnalysis:\n- 75%-tile response time for 'all' requests, stands at [75Pct value] ms.\n- Average throughput for 'all' requests, stands at [rpm value] r/s.\n- The test results are [satisfactory/not satisfactory] as only [value]% of the Non-Functional Requirements (NFRs) are met.\n- The throughput appears to be [relatively stable overall/unstable overall], with the RPS line maintaining a general [describe the throughput trend] trend in line with the [increase in/fixed number of/decrease in] Active Users.\n- [Provide a highlevel overview of the behavior of response times]\n- [Provide a highlevel overview of the behavior of CPU usage]\n- [Provide a highlevel overview of the behavior of Memory usage]\n\nTop 5 slowest requests (Based on 75%-tile):\n- [request name]: 75%-tile response time of [value] ms.\n\nRequests with high error rate:\n[If there are requests with a high error rate, include them]\n\nRequests that do not meet NFRs:\n[If there are requests that don't meet the NFRs, include them]\n\nRecommendations:\n- [Provide recommendations for addressing any identified issues. Ensure that each recommendation is clearly stated and supported by the data].\n@@@@\n\nObservations from aggregated data analysis:\n[aggreagted_data_analysis]\n\nObservations from graphs analysis:\n[graphs_analysis]\n\nNFRs summary\n[nfr_summary]"
        summary_template_group  = "Role: Lead Performance Analyst \nContext: You are in the process of preparing an overview of several performance tests. \nTask: Review the results of multiple tests and create a high-level summary of the findings. \nTest results:"
        prompts              = pkg.get_prompts(self.project_id)
        if len(prompts) == 0:
            self.save_prompt({"prompt":default_graph_prompt, "type": "graph", "place": "default", "id": None })
            self.save_prompt({"prompt":aggreagted_table, "type": "aggreagted_table", "place": "default", "id": None })
            self.save_prompt({"prompt":summary_template, "type": "template", "place": "default", "id": None })
            self.save_prompt({"prompt":summary_template_group, "type": "template_group", "place": "default", "id": None })
        
    def save_prompt(self, form):
        pkg.save_prompt(self.project_id, form)

    def get_prompts(self):
        return pkg.get_prompts(self.project_id)